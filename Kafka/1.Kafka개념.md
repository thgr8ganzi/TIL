
## Apache Kafka

### 탄생

* 링크드인 내부에서 개발된 메시지 큐 시스템
* 소스애플리케이션과 타겟애플리케이션간의 비동기식 메시지 전달을 위한 시스템
* 아파치 카프카는 각각의 애플리케이션끼리 연결해 데이터를 처리하는것이 아니라 한곳에 모아 중앙집중화했다
* 카프카는 토픽이 존재하는데 RDB 의 테이블 개념
* 토픽은 한개이상 파티션 존재
* 특정 데이터를 보내는것은 프로듀서가 한다
* 적재된 데이터는 파티션으로 들어가는데 이게 Queue 구조이고 FIFO 방식이다
* 컨슈머는 데이터를 받는존재
* 프로듀서 -> 파티션 -> 컨슈머
* 파티션의 데이터는 컨슈머가 가져가더라도 삭제되지 안는다.
* 컨슈머가 어떤데이터까지 읽었는지는 커밋이라는 개념이 존재한다

### 카프카가 데이터 파이프라인으로 적합한 이유

* 높은 처리량
  * 데이터를 송수신할때 묶어서 보내기 때문에 처리량이 높다
  * 동일 목적의 데이터를 여러 파티션에 분배하고 병렬처리 가능
  * 데이터를 여러 파티션에 분배하고 병렬처리 가능
* 확장성
  * 데이터가 적을땐 클럴스터의 브로커를 최소한으로 유지하다 스케일 아웃 가능
  * 한개의 클러스터는 여러개의 브로커 가질수 있음 반대로 스케일 인도 가능
  * 무중단으로 확장, 축소 가능
* 영속성
  * 데이터가 종료되더라도 데이터는 삭제되지 않음
  * 카프카는 파일시스템에 저장하기 때문
  * 운영체제 영역에서 페이징 캐시 영역으로 메모리를 따로 생성하지 않아서 빠르다
  * 디스크 기반 파일 시스템 활용
* 고가용성
  * 프로듀서로 데이터를 받은 브로커는 다른 브로커로 데이터를 복제
  * 한개의 브로커가 다운되더라도 다른 브로커가 데이터를 처리
  * 온프레미스 서버랙 또는 퍼블릭 클라우드 리전 단위 장애도 데이터를 안전하게 복제할수 있는 브로커 옵션 존재

### 카프카 아키텍쳐와 미래

* 기존 원천데이터 + 파생데이터 + 서빙데이터 로 나누어져있었는데 그래서 람다 아키테쳐가 나옴
* 람다 아키텍처는 배치레이어 + 서빙레이어 + 스피드레이어로 이루어짐
  * 배치레이어 : 데이터를 수집하고 일괄 처리하는 레이어
  * 스피드레이어 : 실시간으로 원천 데이터를 분석하는 레이어(카프카)
  * 서빙레이어 : 사용자에게 데이터를 제공하는 레이어
* 람다 아키텍처 한계
  * 배치레이어와 스피드레이어가 명확히 나누어져 있지만 데이터분석, 처리시 필요한 로직이 2벌이 된다는 단점
  * 배치데이터, 실시간데이터 융합시 다소 유연하지 못함
* 카파아키텍쳐 는 스피드레이어와 서빙레이어로 람다아키텍처 단점 보완
  * 모든 배치데이터를 스피드레이어에서 처리
  * 데이터 스트림형태로 들어오면 변환기록 로그와 배치데이터 스냅샷을 통해 스피드레이어에 적재
  * 카프카는 데이터 하나당 타임스태프를 가지고 있어서 처리 가능
  * 카프카는 타임스탬프의 시간을 가져와서 구체화된 뷰를 만들어 배치처럼 처리
* 스트리밍 데이터 레이크 아키텍처
  * 스피드레이어만 존재하는 아키텍처
  * 카프카가 배치데이터, 서빙레이어 데이터도 모두 처리

------------------------

### 카프카 생태계

* 카프카 클러스터 내에는 목적에 따라서 토픽이 생성
* 프로듀서는 토픽에 데이터를 넣어주고 컨슈머가 가져감
* 데이터를 stateful, stateless 하게 토픽에 넣고싶을땐 토픽을 통해 스트림즈에 넣어준다
* 커넥트는 데이트 파이프라인을 운영하는 툴
* 소스커넥트는 프로듀서, 싱크 커넥트는 컨슈머 역활
* 소스커넥터는 특정 DB 나 소스 애플리케이션으로부터 토픽에 넣는 역활
* 싱크커넥트는 타겟 애플리케이션으로 토픽에서 데이터를 보내는 컨슈머 역활

### 카프카 브로커와 클러스터, 주키퍼

* 브로커는 프로듀서, 컨슈머와 반드시 통신하는 역활
* 주키퍼는 카프카를 운용하기 위해서 반드시 필요(3.0이상은 주키퍼 필요없음)
* 한개의 클러스터는 여러개의 브로커 가지는데 브로커는 한개의 서버에서 동작
* 브로커는 데이터를 분산저장하여 하나하나가 프로세스 역활을 하는 애플리케이션
* 세개이상의 브로커는 하나의 클러스터로 묶는것이 일반적이고 안정적

### 카프카 클러스터가 연결된 주키퍼

* 카프카 클러스터가 실행하기 위해선 주키퍼 필요
* 주키퍼의 서로다른 znode 에 클러스터 지정
* root znode 에 각 클러스터별 znode 생성 클러스터 실행시 root 가 아닌 하위 znode 로 설정
* 카프카 3.0 부터는 주키퍼 필요없음 

### 브로커 역활 - 컨트롤러, 데이터삭제, 컨슈머오프셋 저장, 코디네이터

* 컨트롤러
  * 다수의 브로커중 한대가 역활
  * 다른 브로커의 상태 체크하고 브로커가 클러스터에 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배
  * 컨트롤러 브로커가 장애 생기면 다른 브로커가 컨트롤러 역활을 한다
* 데이터삭제
  * 컨슈머가 데이터를 가져가더라도 토픽 데이터 삭제되지 않음
  * 컨슈머나 프로듀서가 데이터 삭제요청을 할수 없고 브로커가 삭제요청을 받아서 삭제
  * 데이터 삭제는 파일단위로 이루어지고 이 단위는 로그세그먼트라 부른다.
  * 로그세그먼트는 다수의 데이터가 들어있기 때문에 특정 데이터를 선별해서 삭제할수 없다
* 컨슈머 오프셋 저장
  * 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기위해 오프셋을 커밋한다.
  * 커밋한 오프셋은 __consumer_offset 토픽에 저장
  * 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리
* 그룹 코디네이터
  * 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역활
  * 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 함
  * 파티션을 컨슈머로 재할당하는 과정을 리밸런스라고 부른다.

### 브로커 역활 - 데이터 저장

* 카프카 실행시 config/server.properties 의 log.dirs 에 지정된 디렉토리에 데이터 저장
* 파일시스템으로 어디에 저장할지 log.dirs 에 지정
* 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리 생성
* 로그 파일은 메시지와 메타데이터 저장
* index 는 메타데이터의 오프셋을 인덱싱한 정보
* timeindex 파일은 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보 담김
* 프로듀서가 보낸 메시지 하나가 레코드 라고한다.

### 로그 세그먼트

* log.segment.bytes : 바이트 단위의 최대 세그먼트 크기 지정 기본값은 1GB
* log.roll.ms(hours) : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 기본값은 7일
* 카프카는 파일시스템을 나눠서 저장하는데 바이트 단위와 시간단위가 있다.
* 오프셋은 레코드의 고유 번호이다.
* 프로듀서가 레코드를 저장하면 active segment 라는 최근 세그먼트에 저장
* 파일이름은 오프셋의 처음 번호로 구성
* 가장 마지막 세그먼트 파일을 액티브 세그먼트라고 한다.
* 액티브 세그먼트는 브로커의 삭제 대상에 포함되지 않는다.
* 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.
