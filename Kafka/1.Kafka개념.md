
## Apache Kafka

### 탄생

* 링크드인 내부에서 개발된 메시지 큐 시스템
* 소스애플리케이션과 타겟애플리케이션간의 비동기식 메시지 전달을 위한 시스템
* 아파치 카프카는 각각의 애플리케이션끼리 연결해 데이터를 처리하는것이 아니라 한곳에 모아 중앙집중화했다
* 카프카는 토픽이 존재하는데 RDB 의 테이블 개념
* 토픽은 한개이상 파티션 존재
* 특정 데이터를 보내는것은 프로듀서가 한다
* 적재된 데이터는 파티션으로 들어가는데 이게 Queue 구조이고 FIFO 방식이다
* 컨슈머는 데이터를 받는존재
* 프로듀서 -> 파티션 -> 컨슈머
* 파티션의 데이터는 컨슈머가 가져가더라도 삭제되지 안는다.
* 컨슈머가 어떤데이터까지 읽었는지는 커밋이라는 개념이 존재한다

### 카프카가 데이터 파이프라인으로 적합한 이유

* 높은 처리량
  * 데이터를 송수신할때 묶어서 보내기 때문에 처리량이 높다
  * 동일 목적의 데이터를 여러 파티션에 분배하고 병렬처리 가능
  * 데이터를 여러 파티션에 분배하고 병렬처리 가능
* 확장성
  * 데이터가 적을땐 클럴스터의 브로커를 최소한으로 유지하다 스케일 아웃 가능
  * 한개의 클러스터는 여러개의 브로커 가질수 있음 반대로 스케일 인도 가능
  * 무중단으로 확장, 축소 가능
* 영속성
  * 데이터가 종료되더라도 데이터는 삭제되지 않음
  * 카프카는 파일시스템에 저장하기 때문
  * 운영체제 영역에서 페이징 캐시 영역으로 메모리를 따로 생성하지 않아서 빠르다
  * 디스크 기반 파일 시스템 활용
* 고가용성
  * 프로듀서로 데이터를 받은 브로커는 다른 브로커로 데이터를 복제
  * 한개의 브로커가 다운되더라도 다른 브로커가 데이터를 처리
  * 온프레미스 서버랙 또는 퍼블릭 클라우드 리전 단위 장애도 데이터를 안전하게 복제할수 있는 브로커 옵션 존재

### 카프카 아키텍쳐와 미래

* 기존 원천데이터 + 파생데이터 + 서빙데이터 로 나누어져있었는데 그래서 람다 아키테쳐가 나옴
* 람다 아키텍처는 배치레이어 + 서빙레이어 + 스피드레이어로 이루어짐
  * 배치레이어 : 데이터를 수집하고 일괄 처리하는 레이어
  * 스피드레이어 : 실시간으로 원천 데이터를 분석하는 레이어(카프카)
  * 서빙레이어 : 사용자에게 데이터를 제공하는 레이어
* 람다 아키텍처 한계
  * 배치레이어와 스피드레이어가 명확히 나누어져 있지만 데이터분석, 처리시 필요한 로직이 2벌이 된다는 단점
  * 배치데이터, 실시간데이터 융합시 다소 유연하지 못함
* 카파아키텍쳐 는 스피드레이어와 서빙레이어로 람다아키텍처 단점 보완
  * 모든 배치데이터를 스피드레이어에서 처리
  * 데이터 스트림형태로 들어오면 변환기록 로그와 배치데이터 스냅샷을 통해 스피드레이어에 적재
  * 카프카는 데이터 하나당 타임스태프를 가지고 있어서 처리 가능
  * 카프카는 타임스탬프의 시간을 가져와서 구체화된 뷰를 만들어 배치처럼 처리
* 스트리밍 데이터 레이크 아키텍처
  * 스피드레이어만 존재하는 아키텍처
  * 카프카가 배치데이터, 서빙레이어 데이터도 모두 처리

------------------------

### 카프카 생태계

* 카프카 클러스터 내에는 목적에 따라서 토픽이 생성
* 프로듀서는 토픽에 데이터를 넣어주고 컨슈머가 가져감
* 데이터를 stateful, stateless 하게 토픽에 넣고싶을땐 토픽을 통해 스트림즈에 넣어준다
* 커넥트는 데이트 파이프라인을 운영하는 툴
* 소스커넥트는 프로듀서, 싱크 커넥트는 컨슈머 역활
* 소스커넥터는 특정 DB 나 소스 애플리케이션으로부터 토픽에 넣는 역활
* 싱크커넥트는 타겟 애플리케이션으로 토픽에서 데이터를 보내는 컨슈머 역활

### 카프카 브로커와 클러스터, 주키퍼

* 브로커는 프로듀서, 컨슈머와 반드시 통신하는 역활
* 주키퍼는 카프카를 운용하기 위해서 반드시 필요(3.0이상은 주키퍼 필요없음)
* 한개의 클러스터는 여러개의 브로커 가지는데 브로커는 한개의 서버에서 동작
* 브로커는 데이터를 분산저장하여 하나하나가 프로세스 역활을 하는 애플리케이션
* 세개이상의 브로커는 하나의 클러스터로 묶는것이 일반적이고 안정적

### 카프카 클러스터가 연결된 주키퍼

* 카프카 클러스터가 실행하기 위해선 주키퍼 필요
* 주키퍼의 서로다른 znode 에 클러스터 지정
* root znode 에 각 클러스터별 znode 생성 클러스터 실행시 root 가 아닌 하위 znode 로 설정
* 카프카 3.0 부터는 주키퍼 필요없음 

### 브로커 역활 - 컨트롤러, 데이터삭제, 컨슈머오프셋 저장, 코디네이터

* 컨트롤러
  * 다수의 브로커중 한대가 역활
  * 다른 브로커의 상태 체크하고 브로커가 클러스터에 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배
  * 컨트롤러 브로커가 장애 생기면 다른 브로커가 컨트롤러 역활을 한다
* 데이터삭제
  * 컨슈머가 데이터를 가져가더라도 토픽 데이터 삭제되지 않음
  * 컨슈머나 프로듀서가 데이터 삭제요청을 할수 없고 브로커가 삭제요청을 받아서 삭제
  * 데이터 삭제는 파일단위로 이루어지고 이 단위는 로그세그먼트라 부른다.
  * 로그세그먼트는 다수의 데이터가 들어있기 때문에 특정 데이터를 선별해서 삭제할수 없다
* 컨슈머 오프셋 저장
  * 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기위해 오프셋을 커밋한다.
  * 커밋한 오프셋은 __consumer_offset 토픽에 저장
  * 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리
* 그룹 코디네이터
  * 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역활
  * 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 함
  * 파티션을 컨슈머로 재할당하는 과정을 리밸런스라고 부른다.

### 브로커 역활 - 데이터 저장

* 카프카 실행시 config/server.properties 의 log.dirs 에 지정된 디렉토리에 데이터 저장
* 파일시스템으로 어디에 저장할지 log.dirs 에 지정
* 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리 생성
* 로그 파일은 메시지와 메타데이터 저장
* index 는 메타데이터의 오프셋을 인덱싱한 정보
* timeindex 파일은 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보 담김
* 프로듀서가 보낸 메시지 하나가 레코드 라고한다.

### 로그 세그먼트

* log.segment.bytes : 바이트 단위의 최대 세그먼트 크기 지정 기본값은 1GB
* log.roll.ms(hours) : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 기본값은 7일
* 카프카는 파일시스템을 나눠서 저장하는데 바이트 단위와 시간단위가 있다.
* 오프셋은 레코드의 고유 번호이다.
* 프로듀서가 레코드를 저장하면 active segment 라는 최근 세그먼트에 저장
* 파일이름은 오프셋의 처음 번호로 구성
* 가장 마지막 세그먼트 파일을 액티브 세그먼트라고 한다.
* 액티브 세그먼트는 브로커의 삭제 대상에 포함되지 않는다.
* 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.

### 세그먼트와 삭제주기

* retention.ms(minutes, hours, days) : 시간 기준으로 세그먼트 삭제 주기(기본 7일)
* retention.bytes : 파티션당 로그 적재 바이트값, 기본값은 -1(지정하지 않음)
* log.retention.check.interval.ms : 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격 기본값은 5분
* 카프카에서 데이터는 세그먼트 단위로 삭제 가능
* 로그 단위 개별 삭제는 불가
* 데이터를 적재할때 또는 데이터를 사용할때 데이터 검증 요

### cleanup.policy=compact

* 토픽 압축 정책은 일반적으로 생각하는 zip 과 같은 압축과는 다른개념
* 압축이란 메시지 키 별로 해당 메시지 키의 레코드중 오래된 데이터를 삭제하는 정책을 뜻한다
* 삭제 정책과 다르게 일부 레코드만 삭제가 될수 있다.
* 압축은 액티브 세그먼트를 제외한 데이터가 대상

### 테일/헤드, 클린/더티

* 테일 영역 : 압축 정책에 의해 압축이 완료된 레코드들 클린 로그, 중복 메시지 키가 없다.
* 헤드 영역 : 압축정책 되기전 레코드, 더티 로그, 중복 메시지 있음

### min.cleanable.dirty.ratio

* 옵션값은 액티브 세그먼트를 제외한 세그먼트에 남아있는 테일영역, 레드영역의 레코드 개수 비율

### 브로커 역활 - 복제(Replication)

* 클러스터로 묶인 브로커중 일부에 장애가 발생해도 데이터가 유실하지 않고 안전하게 사용
* 데이터 복제는 파티션 단위
* replication factor 개수 로 지정
* 복제 파티션은 리더와 팔로워로 구성
* 리더 파티션으로 부터 데이터를 가져와서 자신의 파티션에 저장하는 과정을 복제라고 한다.

### 브로커 장애 발생 경우

* 브로커가 다운되면 팔로워중 하나가 리더 파티션이 된다.
* 프로듀서, 컨슈머 통신은 리더가 하기 떄문에
* 데이터가 유실되어도 무관하고 데이터 처리속도가 중요하면 1로 설정
* 유실 일어나면 안되는 경우 3 으로 설정

### ISR(In-Sync Replica)

* 리더 와 팔로워 파티션 모두 싱크된 상태(offset 크기가 같음)
* 데이터 유실이 발생하더라도 서비스를 중단하지 않고 지속저긍로 토픽을 사용하고 싶다면 ISR 이 아닌 팔로워 파티션을 리더로 선출
* unclean.leader.election.enable=true : 유실 감수, 복제 안된 팔로워 파티션 리더로 승급
* unclean.leader.election.enable=false : 유실감수 안함, 해당 브로커가 복구될때까지 중단

### 토픽 파티션

* 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위
* 토픽은 1개이상 파티션 소유
* 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장 레코드 라고 함
* 파티션은 큐 구조
* 레코드는 컨슈머가 가져감
* 카프카는 pop 하지 않음

### 토픽 생성시 파티션 배치 방법

* 파티션 0번 브로커 부터 round-robin 방식으로 리더 파티션 생성
* 선형 확정을 통해 데이터가 많아지더라도 자연스럽게 대응

### 파티션 개수와 컨슈머 개수 처리량

* 파티션은 카프카의 병렬처리 핵심
* 그룹으로 묶인 컨슈머는 레코드를 병렬 처리할수 있게 매칭
* 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과 볼수있음

### 파티션 개수를 줄이는것은 불가능

* 파티션 개수를 줄이는것은 지원하지 않음
* 파티션을 늘릴땐 신중히 정해야함
* 한번 늘리면 줄이는것이 불가능해 토픽을 삭제하고 다시 재생성 해야함

### 레코드

* 타임스탬프, 헤더, 메시지키, 메시지값, 오프셋 으로 구성
* 프로듀서가 생성한 레코드가 브로커에 전송되면 오프셋 타임스탬프 지정
* 브로커에 적재된 레코드는 수정할수 없음
* 로그 리텐션 기간 또는 용량에 따라 삭제가능
* 타임스탬프
  * 프로듀서 레코드의 생성 시간이 들어감
  * 브로커 적재시간 으로 설정할수도 있음
* 오프셋
  * 프로듀서가 생성한 레코드에는 존재하지 않음
  * 오프셋은 0부터 1씩 증가함
  * 각 메시지는 파티션 별로 고유한 오프셋을 가지고 컨슈머에서 중복 처리를 방지하기 위한 목적
* 헤더
  * key/value 데이터 추가 할수 있음
  * 데이터 프로세싱에 참고할 만한 정보를 담아서 사용할수 있음
* 메시지 키
  * 메시지값의 분류를 위한 용도(파티셔닝)
  * 메시지키는 필수값 아니며 null 기본
  * null 인 레코드는 특정 파티션에 라운드 로빈으로 전달
  * null 이 아니면 해쉬값에 의해 특정 파티션에 매핑
* 메시지 값
  * 실질적으로 처리할 데이터가 담기는 공간
  * 제네릭으로 지정
  * flaot, double, int, long, string, byte[] 등 가능
  * 직렬화/역질렬화 클래스를 만들어 사용 할수도 있음
  * 브로커에 저장된 레코드의 메시지값은 어떤 포맷으로 직렬화 되어 저장되어있는지 알수없음
  * 컨슈머는 미리 역 직렬화 포맷을 알고있어야 함

### 토픽이름 제약조건

* 빈 문자열 토픽이름 x
* 토픽이름 마침표(x), 길이 249 미만, 대소문자 구분 x
* 마침표 언더바 동시에 사용 x
* 하이픈, 영어 대소문자, 숫자 사용 가능

### 의미있는토픽 이름 작명

* 토픽은 데이터의 얼굴
* 이름이 모호한 토픽은 유지보수시 큰 어려움
* 카프카는 이름 변경 지원 하지 안흥ㅁ
* 삭제후 다시 생성해야함

### 토픽 작명 템플릿

* 환경.팀명.애플리케이션명.메시지타입
* 프로젝트명.서비스명.환경.이벤트명
* 환경.서비스명.jira-번호.메시지타입
* 카프카-클러스터-명.환경.서비스명.메시지타입

### 클라이언트 메타데이터

* 카프카 클라이언트 -> 메타데이터 요청 -> 카프카 클러스터
* 카프카 클라이언트 <- 메타데이터 응답 <- 카프카 클러스터
* 카프카 클라이언트는 통신하고자 하는 리더 파티션의 우치를알기 위해 데이터를 주고(프로듀서) 받기(컨슈머전에 메타데이터를 브로커로부터 전달받음

### 클라이언트 메타데이터 이슈 발생한 경우

* 카프카 클라이언트는 반드시 리더 파티션과 통신
* 메타데이터가 현재 파티션 상태에 맞게 리프래시 되지 않은 상태에서 잘못된 브로커로 데이터 요청히면 LeaderNotAvailableException 발생
* 이 에러가 자주 발생하면 메타데이터 리프래시 간격 확인하고 클라이언트가 정상적인 메타데이터 가지고 있는지 확인

