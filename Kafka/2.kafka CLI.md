
## kafka CLI

-------------------------

### kafka-topics.sh

* 카프카 토픽을 생성하려면 클러스터 정보와 카프카 토픽이름을 알필요가 있다.
* `bin/kafka-topics.sh --bootstrap-server [카프카이름]:[포트] --create` 명령어로 카프카 토픽을 만들수 있다.
* `--dscribe` 옵션을 사용하면 토픽의 정보를 확인할 수 있다.
* `-list` 명령어로 카프카 토픽 리스트를 확인할 수 있다.
* `--alter` 명령어로 토픽의 설정을 변경할 수 있다.
* 파티션 개수를 늘릴수는 있지만 줄일수 없다.
* `kafka-topics --bootstrap-server [카프카 브로커 주소] --create --topic [토픽 이름] --partitions [파티션 개수] --replication-factor [replication-factor 개수] --config retention.ms=[토픽 메세지 보관 시간]` 명령어로 토픽을 생성할 수 있다.
* `kafka-topics --bootstrap-server kafka1:9092 --create --topic hello --partitions 1 --replication-factor 1 --config retention.ms=172800000`
* `kafka-topics --bootstrap-server [카프카 브로커 주소] --delete --topic [토픽 이름]` 명령어로 토픽을 삭제할 수 있다.

### kafka-configs.sh

* 토픽의 일부 옵션을 설정하기 위해 사용한다.
* `--alter` 옵션을 사용하면 토픽의 설정을 변경할 수 있다.
* `--add-config` 옵션을 사용하면 토픽의 설정을 추가할 수 있다.
* `--broker, --all, --describe` 옵션을 사용하면 브로커, 모든 토픽, 토픽의 설정을 확인할 수 있다.

### kafka-console-producer.sh

* 카프카 토픽에 메세지를 보내기 위해 사용한다.
* 문자를 작성하고 엔터키를 누르면 별다른 응닶없이 메시지가 전송
* `kafka-console-producer --bootstrap-server [카프카 브로커 주소] --topic [토픽 이름] --property "parse.key=true" --property "key.separator=:"` 명령어로 메시지 키를 가지는 레코드를 보낼 수 있다.
* 메시지 키를 가지는 레코드를 전송하기 위해 몇가지 추가 옵션을 작성
* key.separator 를 선언하지 않으면 기본 설정은 tab delimiter(\t)이다.
* 동일한 메시지 키는 동일한 파티션에 들어간다.
* 특정 데이터의 순서를 지키고 싶을땐 메시지 키를 지정해서 보낸다.
* 메시지 키를 설정하지 않으면 null 이고 레코드는 라운드 로빈으로 들어간다.

### kafka-console-consumer.sh

* 특정 토픽에 있는 데이터를 컨슘 해서 안의 데이터를 조회
* `kafka-console-consumer --bootstrap-server [카프카 브로커 주소] --topic [토픽 이름]` 명령어로 토픽의 데이터를 조회할 수 있다.
* `--from-beginning` 옵션을 사용하면 토픽의 처음부터 데이터를 조회할 수 있다.
* 메시지 키와 값을 함꼐 확인하려면 `--property print.key=true` 옵션을 사용한다.
* `--property ket.separator="-` 옵션을 사용하면 메시지 키-값으로 구분할 수 있다.
* `--max-messages [숫자]` 옵션을 사용하면 특정 개수의 메시지만 조회할 수 있다.
* `--partition [파티션 번호]` 옵션을 사용하면 특정 파티션의 데이터만 조회할 수 있다.
* `--group [그룹 이름]`컨슈머 그룹으로 기반한 콘솔 컨슈머가 동작한다
* 그룹의 용도는 특정 오프셋 까지 읽었다고 커밋용도로 사용
* 컨슈머 그룹을 사용하면 컨슈머가 특정 오프셋까지 읽었다고 커밋할 수 있다.
* 커밋데이터는 __consumer_offsets 토픽에 저장된다.

### kafka-consumer-groups.sh

* 컨슈머 그룹의 정보를 확인하고 관리하기 위해 사용한다.
* `kafka-consumer-groups --bootstrap-server [카프카 브로커 주소] --list` 명령어로 컨슈머 그룹 리스트를 확인할 수 있다.
* `kafka-consumer-groups --bootstrap-server [카프카 브로커 주소] --describe --group [그룹 이름]` 명령어로 컨슈머 그룹의 정보를 확인할 수 있다.
* 어떤 토픽 대상으로 몇번 오프셋의 레코드를 가져갔는지, 현재 상태, 오프셋의 위치, 컨슈머 렉 등을 확인할 수 있다.
* 컨슈머 렉 : 마지막 레코드의 오프셋과 현재 오프셋의 차이
* `kafka-consumer-groups --bootstrap-server [카프카 브로커 주소] --reset-offsets --group [그룹 이름] --topic [토픽 이름] --to-earliest` 명령어로 컨슈머 그룹의 오프셋을 초기화할 수 있다.
* `--to-earliest` 옵션을 사용하면 토픽의 가장 처음부터 데이터를 가져올 수 있다.
* `--to-latest` 옵션을 사용하면 토픽의 가장 마지막부터 데이터를 가져올 수 있다.
* `--to-offset [오프셋 번호]` 옵션을 사용하면 특정 오프셋부터 데이터를 가져올 수 있다.
* `--to-current` 옵션을 사용하면 현재 오프셋부터 데이터를 가져올 수 있다.
* `--to-date [날짜]` 옵션을 사용하면 특정 날짜부터 데이터를 가져올 수 있다.
* `--shift-by [숫자]` 현재 컨슈머 오프셋에서 앞뒤로 옮겨서 리셋
* `--execute` 옵션을 사용하면 오프셋을 초기화할 수 있다.
* 카프카 토픽의 오프셋 데이터는 삭제 되지 않는다.

### 그외 커맨드

* `kafka-producer-perf-test.sh` : 프로듀서의 성능을 테스트하기 위해 사용한다.
* `kafka-reassign-partitions.sh` : 파티션을 재할당하기 위해 사용한다.
* 리더 파티션과 팔로워 파티션의 위치를 변경하고 클러스터 단위에서 리더 파티션을 자동 리밸런싱 해준다.
* `kafka-delete-record` : 해당 오프셋 까지 레코드를 삭제한다.
* `kafka-dump-log` : 특정 파티션의 로그를 확인한다.

### kafka 토픽 생성 방법

* 토픽 생성 상황은 2가지가있다
* 첫번째는 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할때
* 두번째는 커맨드 라인 툴로 명시적으로 토픽을 생성하는것 이다.
