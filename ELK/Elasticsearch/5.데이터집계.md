## 데이터 집계

* 데이터를 그룹화해서 각종 통계 지표를 제공하기 위해 엘리스틱서치에서 집계 기능 공식적 제공
* SQL group by 과 비슷
* 유료버전 X-pack 이용시 더욱 간단한 ansi SLQ 구문 질의 가능

### 엘라스틱서치 데이터 분석

* 일반적으로 통계프로그램은 배치 방식으로 데이터 처리
* 엘라스틱서치는 많은 양의 데이터를 조각내어 관리

### 집계에 사용되는 기술

* 캐시
  * 집계쿼리로 값을 조회하면 엘라스틱서치의 마스터 노드가 여러 노드에 있는 데이터를 집계해 질의에 답변
  * 캬시의 크기는 일반적으로 힙 메모리의 1%를 할당
  * conf/elasticsearch.yml 파일 수정해 활성화
  * 캐시종류
    * node query cache
      * 노드의 모든 샤드가 공유하는 LRU 캐시
    * shard request cache
      * 샤드에서 수행된 쿼리의 결과를 캐싱
    * field data cache
      * 필드 데이터 캐시
      * 엘라스틱 서치가 필드에서 집계 연산을 수행할때 모든 필드값을 메모리에 로드, 집계가 계산되는 동안 필드의 값을 메모리에 보관

### Aggregation API

* 엘라스틱 서치는 집계시 문서를 평가한 후 기준에 만족하는 문서들을 하나로 그룹화
* 그룹화한 집합을 토대로 집계를 수행하고 집계가 끝나면 버킷목록에 속한 문서의 집합 출력
* 집계 방식 종류
  * 버킷집계
    * 쿼리 결과로 도출된 도큐먼트 집합에 대해 특정 기준으로 나눈 다음 나눠진 도큐먼트들에 대한 산술 연산 수행
  * 매트릭 집계
    * 쿼리 결과로 도출된 도큐먼트 집합에서 필드의 값을 더하거나 평균을 구하는 등의 산술 연산 수행
  * 파이프라인 집계
    * 다른 집계 또는 관련 메트릭 연산의 결과 집계
  * 행렬집계
    * 버킷 대상이 되는 도큐먼트의 여러 필드에서 추출한 값으로 행렬 연산 수행 다양한 통계정보를 제공
* 엘라스틱 서치가 강력한 이유는 집계를 중첨해 사용할수 있다는점
* 하위 집계가 상위 집계의 버킷을 다시 집계
```
"aggregations" : {
  "<aggregation_name>" : {
    "<aggregation_type>" : {
      <aggregation_body>
    }
    [, "meta" : { [<meta_data_body>] } ]?
    [, "aggregations" : { [<sub_aggregation>]+ } ]?
  }
  [, "<aggregation_name_2>" : { ... } ]*
}
```

### 메트릭 집계

* 메트릭 집계를 사용해 특정 필드에 대한 합이나 평균을 계산하거나 다른집계와 중첩해 특정필드의 _source 에 대한 통계를 계산
```
{
  "aggs": {
    "<집계 이름>": {
      "<집게타입>": {
        "field": "<필드명>"
      }
    }
  }
}
```

### 합산집계

* 단일 숫자 메트릭 집계, 해당서버로 얼마만큼 데이터가 유입됐는지 집계
```
{
  "aggs": {
    "total_bytes": {
      "sum": {
        "field": "bytes"
      }
    }
  }
}
```

### 평균집계

* 단일숫자 메트릭 집계, 서버로 유입된 데이터의 평균값
```
{
  "aggs": {
    "avg_bytes": {
      "avg": {
        "field": "bytes"
      }
    }
  }
}
```

### 최소값 집계

* 단일숫자 메트릭 집계, 가장 작은값 구하기
```
{
  "aggs": {
    "min_bytes": {
      "min": {
          "field": "bytes"
      }
    }
  }
}
```

### 최대값 집계

* 단일숫자 메트릭 집계, 가장 큰값 구하기
```
{
  "aggs": {
    "max_bytes": {
      "max": {
        "field": "bytes"
      }
    }
  }
}
```

### 개수 집계

* 단일숫자 메트릭 집계, 해당 서버로 유입된 데이터의 개수
```
{
  "aggs": {
    "count_bytes": {
      "value_count": {
        "field": "bytes"
      }
    }
  }
}
```

### 확장 통계 집계

* 결과값이 여러개인 다중 숫자 메트릭 집계
```
{
  "aggs": {
    "extended_stats_bytes": {
      "extended_stats": {
        "field": "bytes"
      }
    }
  }
}
```

### 카디널리티 집계

* 단일 숫자 메트릭 집계
* 개수 집합과 유사하게 횟수를 계산, 중복된값 제외 고유한 값에 집계 수행
* 모든 문서에 대해 중복된 값을 집계하는것은 성능에 큰 영향을 줄수 있기 떄문에 근사치를 통해 집계를 수행한다.
```
{
  "query" : {
    "constant_score" : {
      "filter" : {
        "match" : { "geoip.country_name" : "United States" }
      }
    }
  }
}
```
* 근사치계산은 HyperLogLog++ 알고리즘을 사용 이알고리즘은 해시를 기반으로 계산
  * 정확성을 위해 메모리를 교환하는 방법 결정
  * 카디널리티가 낮은 집합일수록 더 뒤어난 정확성
  * 수십억개의 고윳값이 존재하더라도 메모리 사용은 정확도 설정에 의존, 고정된 메모리 사용

### 백분위 수 집계

* 다중 숫자 메트릭 집계에 해당
* 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을때 백분율로 나타낸 특정 위치의 값을 이르는 용어
```
{
  "aggs": {
    "percentiles_bytes": {
      "percentiles": {
        "field": "bytes"
      }
    }
  }
}
```

### 버킷집계

* 메트릭 집계와는 다르게 메트릭을 계산하지 않고 버킷을 생성
* 생성되는 버킷은 쿼리와 함계 수행되어 쿼리 결과에 따른 컨텍스트 내에서 집계 이뤄짐
* 이렇게 집계된 버킷은 또 다시 하위에서 집계를 한번더 수행해서 집계된 결과에 대해 중첩된 집계를 수행하는것 가능
* 버킷을 생성한다는것은 집계된 결과 데이터 집합을 메모리에 저장한다는 의미이기 때문에 중첩되는 단계가 깊어질수록 메모리 사용량은 점점더 증가해서 성능에 악영향을 줄수 있다.
* search.max_buckets 설정을 통해 버킷의 최대 개수를 제한할수 있다.

### 집계 종류

* 범위집계
* 날짜 범위 집계
* 히스토그램 집계
* 날짜 히스토그램 집계
* 텀즈 집계

### 파이프라인 집계

* 다른 집계와 달리 쿼리 조건에 부합하는 문서에 대해 집계를 수행하느것이 아니라 다른 집계로 생성된 버킷을 참조해서 집계 수행
* 파이프라인 집계에는 부모 형제 두가지 유형이 있다.
* buckets_path 파라미터를 사용해 참조할 집계의 경로를 지정함으로써 체인 형식으로 집계 간의 연산이 이뤄진다..
